{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding Spotify Audio Analysis to Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What Do I Want to Keep?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/audio_analysis/46n2EGFnPC3tzWCN1Aqe26.json', 'r') as f:\n",
    "    example = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "duration\n",
      "confidence\n",
      "loudness\n",
      "tempo\n",
      "tempo_confidence\n",
      "key\n",
      "key_confidence\n",
      "mode\n",
      "mode_confidence\n",
      "time_signature\n",
      "time_signature_confidence\n"
     ]
    }
   ],
   "source": [
    "for k, v in example['sections'][0].items():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(example['sections'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Stats for Audio Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "confidence                     0.692538\n",
       "duration                      21.904615\n",
       "key                            5.384615\n",
       "key_confidence                 0.558000\n",
       "loudness                      -7.889308\n",
       "mode                           0.692308\n",
       "mode_confidence                0.594923\n",
       "start                        136.534450\n",
       "tempo                        166.052538\n",
       "tempo_confidence               0.426615\n",
       "time_signature                 4.000000\n",
       "time_signature_confidence      0.954385\n",
       "dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "confidence                      0.070495\n",
       "duration                       45.829279\n",
       "key                            15.923077\n",
       "key_confidence                  0.038505\n",
       "loudness                       15.730314\n",
       "mode                            0.230769\n",
       "mode_confidence                 0.013016\n",
       "start                        7860.392668\n",
       "tempo                           0.024245\n",
       "tempo_confidence                0.011827\n",
       "time_signature                  0.000000\n",
       "time_signature_confidence       0.018383\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating Through json's to Determine Overall Shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_list = []\n",
    "\n",
    "with open('../data/audio_analysis_list.csv', 'r') as f:\n",
    "    analysis = csv.reader(f)\n",
    "    for song in analysis:\n",
    "        analysis_list.extend(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'7zvKFw17XyoBUx9mHiwzPy.json'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis_sorter(lst):\n",
    "    mean_dicts = []\n",
    "    var_dicts = []\n",
    "    count = 0\n",
    "    for record in lst:\n",
    "        with open('../data/audio_analysis/{}'.format(record), 'r') as f:\n",
    "            analysis = json.load(f)\n",
    "            if isinstance(analysis, dict):\n",
    "                if 'sections' in analysis:\n",
    "                    try:\n",
    "                        mean_dict = {}\n",
    "                        var_dict = {}\n",
    "                        df = pd.DataFrame(analysis['sections'])\n",
    "                        mean = df[['confidence', 'duration', 'loudness', 'mode', 'mode_confidence',\n",
    "                                   'tempo', 'tempo_confidence']].mean().to_dict()\n",
    "                        var = df[['confidence', 'duration', 'loudness', 'mode', 'mode_confidence',\n",
    "                                   'tempo', 'tempo_confidence']].var().to_dict()\n",
    "                        mean_dict[record.replace('.json', '')] = mean\n",
    "                        var_dict[record.replace('.json', '')] = var\n",
    "                        mean_dicts.append(mean_dict)\n",
    "                        var_dicts.append(var_dict)\n",
    "                    except:\n",
    "                        mean_dict = {}\n",
    "                        var_dict = {}\n",
    "                        mean_dict[(record.replace('.json',''))] = 'Unable to calculate mean of section features'\n",
    "                        var_dict[(record.replace('.json',''))] = 'Unable to calculate variance of section features'\n",
    "                        mean_dicts.append(mean_dict)\n",
    "                        var_dicts.append(var_dict)\n",
    "            count += 1\n",
    "            if count % 5000 == 0:\n",
    "                print(\"Completed {} files\".format(count))\n",
    "            if count % 5000 == 0:\n",
    "                with open('../data/section_var_summary_{}.json'.format(count), 'w') as f:\n",
    "                    json.dump(var_dicts, f)\n",
    "                    var_dicts.clear()\n",
    "                with open('../data/section_mean_summary_{}.json'.format(count), 'w') as f:\n",
    "                    json.dump(mean_dicts, f)\n",
    "                    mean_dicts.clear()\n",
    "    return mean_dicts, var_dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed 5000 files\n",
      "Completed 10000 files\n",
      "Completed 15000 files\n",
      "Completed 20000 files\n"
     ]
    }
   ],
   "source": [
    "mean_dicts, var_dicts = analysis_sorter(analysis_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'6k9L7kTBzjXY0GfazHYqCg': {'confidence': 0.6483,\n",
       "  'duration': 20.578667000000003,\n",
       "  'loudness': -9.3965,\n",
       "  'mode': 0.8,\n",
       "  'mode_confidence': 0.46769999999999995,\n",
       "  'tempo': 142.13690000000003,\n",
       "  'tempo_confidence': 0.2643}}"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_dicts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'6k9L7kTBzjXY0GfazHYqCg': {'confidence': 0.04827756666666666,\n",
       "  'duration': 88.7212888207789,\n",
       "  'loudness': 85.8691118333333,\n",
       "  'mode': 0.17777777777777778,\n",
       "  'mode_confidence': 0.03472067777777778,\n",
       "  'tempo': 1.7909101000000023,\n",
       "  'tempo_confidence': 0.007427788888888888}}"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_dicts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining Summary Stats Docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean\n",
    "with open('../data/section_mean_summary_5000.json', 'r') as f:\n",
    "    section_mean_summary_5000 = json.load(f)\n",
    "with open('../data/section_mean_summary_10000.json', 'r') as f:\n",
    "    section_mean_summary_10000 = json.load(f)\n",
    "with open('../data/section_mean_summary_15000.json', 'r') as f:\n",
    "    section_mean_summary_15000 = json.load(f)\n",
    "with open('../data/section_mean_summary_20000.json', 'r') as f:\n",
    "    section_mean_summary_20000 = json.load(f)\n",
    "\n",
    "#var\n",
    "with open('../data/section_var_summary_5000.json', 'r') as f:\n",
    "    section_var_summary_5000 = json.load(f)\n",
    "with open('../data/section_var_summary_10000.json', 'r') as f:\n",
    "    section_var_summary_10000 = json.load(f)\n",
    "with open('../data/section_var_summary_15000.json', 'r') as f:\n",
    "    section_var_summary_15000 = json.load(f)\n",
    "with open('../data/section_var_summary_20000.json', 'r') as f:\n",
    "    section_var_summary_20000 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dicts.extend(section_mean_summary_5000)\n",
    "mean_dicts.extend(section_mean_summary_10000)\n",
    "mean_dicts.extend(section_mean_summary_15000)\n",
    "mean_dicts.extend(section_mean_summary_20000)\n",
    "\n",
    "var_dicts.extend(section_var_summary_5000)\n",
    "var_dicts.extend(section_var_summary_10000)\n",
    "var_dicts.extend(section_var_summary_15000)\n",
    "var_dicts.extend(section_var_summary_20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23125, 23125)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mean_dicts), len(var_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['6k9L7kTBzjXY0GfazHYqCg'])\n",
      "dict_keys(['6kAS4yj3wHJXcLp93vr5aG'])\n"
     ]
    }
   ],
   "source": [
    "for e in var_dicts[:2]:\n",
    "    print(e.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_mean = pd.DataFrame(columns=['confidence', 'duration', 'loudness', 'mode',\n",
    "                                    'mode_confidence', 'tempo', 'tempo_confidence'])\n",
    "\n",
    "for e in mean_dicts:\n",
    "    section_mean.loc[list(e.keys())[0]] = list(e.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_var = pd.DataFrame(columns=['confidence', 'duration', 'loudness', 'mode',\n",
    "                                    'mode_confidence', 'tempo', 'tempo_confidence'])\n",
    "\n",
    "for e in var_dicts:\n",
    "    section_var.loc[list(e.keys())[0]] = list(e.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_mean.to_csv('../data/spotify_section_means.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "section_var.to_csv('../data/spotify_section_var.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How Many Entries did not have Summary Stats?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23124"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(analysis_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23124"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(section_analysis_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for record in section_analysis_summary:\n",
    "    for k, v in record.items():\n",
    "#         for _, value in v.items():\n",
    "        if 'Unable to calculate mean & variance of section features' in v.values():\n",
    "            count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Section Analysis to df\n",
    "\n",
    "# to-do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-83ef30ee1d5d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msec_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msection_analysis_summary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m                     mgr = _arrays_to_mgr(arrays, columns, index, columns,\n\u001b[0;32m--> 400\u001b[0;31m                                          dtype=dtype)\n\u001b[0m\u001b[1;32m    401\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                     mgr = self._init_ndarray(data, index, columns, dtype=dtype,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_arrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m   7357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7358\u001b[0m     \u001b[0;31m# don't force copy because getting jammed in an ndarray anyway\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 7359\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_homogenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7361\u001b[0m     \u001b[0;31m# from BlockManager perspective\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_homogenize\u001b[0;34m(data, index, dtype)\u001b[0m\n\u001b[1;32m   7667\u001b[0m                 \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_multiget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7668\u001b[0m             v = _sanitize_array(v, index, dtype=dtype, copy=False,\n\u001b[0;32m-> 7669\u001b[0;31m                                 raise_cast_failure=False)\n\u001b[0m\u001b[1;32m   7670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7671\u001b[0m         \u001b[0mhomogenized\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_sanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure)\u001b[0m\n\u001b[1;32m   4094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4095\u001b[0m             \u001b[0;31m# we will try to copy be-definition here\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4096\u001b[0;31m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_try_cast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4097\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4098\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExtensionArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_try_cast\u001b[0;34m(arr, take_fast_path)\u001b[0m\n\u001b[1;32m   4042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4043\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4044\u001b[0;31m             \u001b[0msubarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_cast_to_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4045\u001b[0m             \u001b[0;31m# Take care in creating object arrays (but iterators are not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4046\u001b[0m             \u001b[0;31m# supported):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mmaybe_cast_to_datetime\u001b[0;34m(value, dtype, errors)\u001b[0m\n\u001b[1;32m   1086\u001b[0m         elif not (is_array and not (issubclass(value.dtype.type, np.integer) or\n\u001b[1;32m   1087\u001b[0m                                     value.dtype == np.object_)):\n\u001b[0;32m-> 1088\u001b[0;31m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_infer_to_datetimelike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/pandas/core/dtypes/cast.py\u001b[0m in \u001b[0;36mmaybe_infer_to_datetimelike\u001b[0;34m(value, convert_dates)\u001b[0m\n\u001b[1;32m    943\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m     \u001b[0minferred_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfer_datetimelike_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ensure_object\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minferred_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'date'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconvert_dates\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sec_df = pd.DataFrame(section_analysis_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Got memory error...gonna have to try something else."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segments\n",
    "\n",
    "I need to separate `pitches` and `timbre` into separate matrices, considering I need to get the mean and variance of each element within each of those arrays. Beyond that, I don't think I'll need any additional values from this listing. Reasons being, that I'm not overly concered with the length of each segment, nor am I concerned with the loundess levels, since they're encapsulated within the `Sections` and audio features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'start': 0.0,\n",
       " 'duration': 0.43651,\n",
       " 'confidence': 1.0,\n",
       " 'loudness_start': -60.0,\n",
       " 'loudness_max_time': 0.31593,\n",
       " 'loudness_max': -15.215,\n",
       " 'pitches': [0.972,\n",
       "  0.851,\n",
       "  0.534,\n",
       "  0.398,\n",
       "  0.574,\n",
       "  0.824,\n",
       "  0.931,\n",
       "  0.95,\n",
       "  0.95,\n",
       "  0.895,\n",
       "  0.936,\n",
       "  1.0],\n",
       " 'timbre': [5.394,\n",
       "  132.335,\n",
       "  40.451,\n",
       "  -169.179,\n",
       "  36.889,\n",
       "  -87.156,\n",
       "  48.281,\n",
       "  -81.004,\n",
       "  -28.624,\n",
       "  11.046,\n",
       "  76.899,\n",
       "  -15.937]}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example['segments'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(None, dtype=object)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empty = np.array(None)\n",
    "empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Grabbing Pitches and Timbre from each Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pitches = np.array(example['segments'][0]['pitches'])\n",
    "timbre = np.array(example['segments'][0]['timbre'])\n",
    "\n",
    "for record in example['segments'][1:]:\n",
    "    new_pitch = np.array(record['pitches'])\n",
    "    new_timbre = np.array(record['timbre'])\n",
    "    pitches = np.vstack((pitches, new_pitch))\n",
    "    timbre = np.vstack((timbre, new_timbre))\n",
    "\n",
    "pitch_means = np.mean(pitches, axis = 0)\n",
    "timbre_means = np.mean(timbre, axis = 0)\n",
    "pitch_var = np.var(pitches, axis = 0)\n",
    "timbre_var = np.var(timbre, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   5.394,  132.335,   40.451, ...,   11.046,   76.899,  -15.937],\n",
       "       [  25.492,  -29.872,  -43.306, ...,  -11.308,   -0.346,   -8.5  ],\n",
       "       [  30.574,   -4.817,  -20.123, ...,   19.59 ,   10.574,   -3.419],\n",
       "       ..., \n",
       "       [  46.967,   61.795,  -93.704, ...,   -9.035,   10.121,    5.212],\n",
       "       [  42.442,   81.447, -104.876, ...,   -2.364,   -1.035,    1.474],\n",
       "       [  31.01 ,   83.512, -200.859, ...,  -28.773, -103.174,   17.048]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timbre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.972,  0.851,  0.534, ...,  0.895,  0.936,  1.   ],\n",
       "       [ 1.   ,  0.734,  0.05 , ...,  0.024,  0.007,  0.01 ],\n",
       "       [ 0.101,  0.211,  1.   , ...,  0.288,  0.146,  0.027],\n",
       "       ..., \n",
       "       [ 0.199,  0.019,  0.007, ...,  0.025,  0.147,  1.   ],\n",
       "       [ 0.106,  0.103,  0.083, ...,  0.514,  1.   ,  0.399],\n",
       "       [ 0.004,  0.004,  0.004, ...,  0.004,  0.004,  0.029]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pitches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0816765 ,  0.10712059,  0.08919524,  0.03346195,  0.12406955,\n",
       "        0.0444795 ,  0.09366547,  0.11206538,  0.08183722,  0.13351742,\n",
       "        0.06099433,  0.09083536])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pitch_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   44.79019062,  2508.65836209,  2092.29554919,  2116.87128229,\n",
       "         818.87857916,   714.00372464,   591.76958189,   551.21101119,\n",
       "         254.27142387,   258.69811317,   293.24686903,   222.48651461])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timbre_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.29137624,  0.37816535,  0.31408911,  0.19801782,  0.41874059,\n",
       "        0.21457426,  0.3793198 ,  0.35321584,  0.32189307,  0.46579505,\n",
       "        0.24158812,  0.28446238])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pitch_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 47.48974554,   4.37188713, -19.12441782, -13.57252772,\n",
       "        32.99183267, -31.4813703 ,  -7.32949406,  -6.3684198 ,\n",
       "       -10.72296535,  -0.08051782,  -8.91219307,  -3.10303465])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timbre_means"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity Check of Pitch / Timbre Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.291376237624 47.4897455446\n"
     ]
    }
   ],
   "source": [
    "sc_list_pitch = []\n",
    "sc_list_timbre = []\n",
    "\n",
    "for record in example['segments']:\n",
    "    sc_list_timbre.append(record['timbre'][0])\n",
    "    sc_list_pitch.append(record['pitches'][0])\n",
    "\n",
    "print(np.mean(sc_list_pitch), np.mean(sc_list_timbre))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks correct, though I'm surprised that grabbing the mean / variance across the 0 access applies to columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Functions to Grab Summary Pitch and Timbre Statistics for Each Song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pt_grabber_sgl(song):\n",
    "    pitches = np.array(song['segments'][0]['pitches'])\n",
    "    timbre = np.array(song['segments'][0]['timbre'])\n",
    "    \n",
    "    for record in song['segments']:\n",
    "        new_pitch = np.array(record['pitches'])\n",
    "        new_timbre = np.array(record['timbre'])\n",
    "        pitches = np.vstack((pitches, new_pitch))\n",
    "        timbre = np.vstack((timbre, new_timbre))\n",
    "\n",
    "    pitch_means = np.mean(pitches, axis = 0)\n",
    "    timbre_means = np.mean(timbre, axis = 0)\n",
    "    pitch_var = np.var(pitches, axis = 0)\n",
    "    timbre_var = np.var(timbre, axis = 0)\n",
    "\n",
    "    return pitch_means, timbre_means, pitch_var, timbre_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pt_grabber(lst):\n",
    "    timbre_means = []\n",
    "    timbre_var = []\n",
    "    pitch_means = []\n",
    "    pitch_var = []\n",
    "    count = 0\n",
    "    for record in lst:\n",
    "        with open('../data/audio_analysis/{}'.format(record), 'r') as f:\n",
    "            analysis = json.load(f)\n",
    "            if isinstance(analysis, dict):\n",
    "                if 'segments' in analysis:\n",
    "                    try:\n",
    "                        pm, tm, pv, tv = pt_grabber_sgl(analysis)\n",
    "                    except:\n",
    "                        response = \"unable to gather summary stats for song {} pitch & timbre\".format(record.replace(\".json\", ''))\n",
    "        try:\n",
    "            timbre_means.append(dict({record.replace(\".json\", \"\"):tm}))\n",
    "            timbre_var.append(dict({record.replace(\".json\", \"\"):tv}))\n",
    "            pitch_means.append(dict({record.replace(\".json\", \"\"):pm}))\n",
    "            pitch_var.append(dict({record.replace(\".json\", \"\"):pv}))\n",
    "        except:\n",
    "            [lists.append(response) for lists in [timbre_means, timbre_var, \n",
    "                                                  pitch_means, pitch_var]]\n",
    "        count += 1\n",
    "        if count % 1000 == 0:\n",
    "            print(\"grabbing {}\".format(count + 1))\n",
    "    return timbre_means, timbre_var, pitch_means, pitch_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grabbing Pitch / Timbre Summary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grabbing 1001\n",
      "grabbing 2001\n",
      "grabbing 3001\n",
      "grabbing 4001\n",
      "grabbing 5001\n",
      "grabbing 6001\n",
      "grabbing 7001\n",
      "grabbing 8001\n",
      "grabbing 9001\n",
      "grabbing 10001\n",
      "grabbing 11001\n",
      "grabbing 12001\n",
      "grabbing 13001\n",
      "grabbing 14001\n",
      "grabbing 15001\n",
      "grabbing 16001\n",
      "grabbing 17001\n",
      "grabbing 18001\n",
      "grabbing 19001\n",
      "grabbing 20001\n",
      "grabbing 21001\n",
      "grabbing 22001\n",
      "grabbing 23001\n"
     ]
    }
   ],
   "source": [
    "timbre_means, timbre_var, pitch_means, pitch_var = pt_grabber(analysis_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23129, 23129, 23129, 23129)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(timbre_means), len(timbre_var), len(pitch_means), len(pitch_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking Lists for Lack of Summary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for e in pitch_var:\n",
    "    if isinstance(e, str):\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tossing Lists into DataFrames + `csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'000xQL6tZNLJzIrtIgxqSl'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(timbre_means[0].keys())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.242242014742054"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(timbre_means[0].values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_df = pd.DataFrame(columns=[\"dim_\" + str(i) for i in range(1, 13)])\n",
    "\n",
    "for e in timbre_means:\n",
    "    tm_df.loc[list(e.keys())[0]] = list(e.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv_df = pd.DataFrame(columns=[\"dim_\" + str(i) for i in range(1, 13)])\n",
    "\n",
    "for e in timbre_var:\n",
    "    tv_df.loc[list(e.keys())[0]] = list(e.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "pm_df = pd.DataFrame(columns=[\"dim_\" + str(i) for i in range(1, 13)])\n",
    "\n",
    "for e in pitch_means:\n",
    "    pm_df.loc[list(e.keys())[0]] = list(e.values())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "pv_df = pd.DataFrame(columns=[\"dim_\" + str(i) for i in range(1, 13)])\n",
    "\n",
    "for e in pitch_means:\n",
    "    pv_df.loc[list(e.keys())[0]] = list(e.values())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Duplicate Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23129, 12), (23129, 12), (23129, 12), (23129, 12))"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm_df.shape, tv_df.shape, pm_df.shape, pv_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_df.drop_duplicates(inplace = True)\n",
    "tv_df.drop_duplicates(inplace = True)\n",
    "pm_df.drop_duplicates(inplace = True)\n",
    "pv_df.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((23124, 12), (23124, 12), (23124, 12), (23124, 12))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tm_df.shape, tv_df.shape, pm_df.shape, pv_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Outputting to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm_df.to_csv('../data/timbre_means.csv')\n",
    "tv_df.to_csv('../data/timbre_var.csv')\n",
    "pm_df.to_csv('../data/pitch_means.csv')\n",
    "pv_df.to_csv('../data/pitch_var.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats to Remove\n",
    "\n",
    "I don't want to keep the following:\n",
    "\n",
    "#### From Sections:\n",
    "- Mean and Variance:\n",
    "  - key, key confidence (these shouldn't be ranked numerically, at least I don't think so)\n",
    "  - start\n",
    "  - time_signature\n",
    "  - time_signature confidence\n",
    "  - tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
